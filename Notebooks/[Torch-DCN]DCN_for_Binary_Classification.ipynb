{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.__version__>='1.2.0', 'Expect PyTorch>=1.2.0 but get {}'.format(torch.__version__)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "imp_dir = '../Implementations'\n",
    "sys.path.insert(1, imp_dir)\n",
    "data_dir = '../Data/criteo'\n",
    "sys.path.insert(1, data_dir)\n",
    "\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(levelname)-6s %(message)s', level=logging.INFO, datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:10:18 INFO   Device in Use: cuda\n",
      "00:10:18 INFO   CUDA Memory: Total 11.17 GB, Cached 0.00 GB, Allocated 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info('Device in Use: {}'.format(DEVICE))\n",
    "torch.cuda.empty_cache()\n",
    "t = torch.cuda.get_device_properties(DEVICE).total_memory/1024**3\n",
    "c = torch.cuda.memory_cached(DEVICE)/1024**3\n",
    "a = torch.cuda.memory_allocated(DEVICE)/1024**3\n",
    "logger.info('CUDA Memory: Total {:.2f} GB, Cached {:.2f} GB, Allocated {:.2f} GB'.format(t,c,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map_dict_pkl_path = os.path.join(data_dir, 'criteo_feature_dict_artifact/categorical_feature_map_dict.pkl')\n",
    "with open(embedding_map_dict_pkl_path, 'rb') as f:\n",
    "    embedding_map_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_artifact_dir = os.path.join(data_dir, 'criteo_train_numpy_artifact')\n",
    "index_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='index', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "value_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='value', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "label_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='label', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:54:29 INFO   Training data loaded after 2611.02s\n",
      "01:12:22 INFO   Test data loaded after 1073.41s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[:10]]),\n",
    ")\n",
    "\n",
    "logger.info('Training data loaded after {:.2f}s'.format(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[10:]]),\n",
    ")\n",
    "\n",
    "logger.info('Test data loaded after {:.2f}s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DCN_BinClf_Torch' from '../Implementations/DCN_BinClf_Torch.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import execution\n",
    "importlib.reload(execution)\n",
    "import DCN_BinClf_Torch \n",
    "importlib.reload(DCN_BinClf_Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCN = DCN_BinClf_Torch.DCN_Layer(len(embedding_map_dict)+60,\n",
    "                                 20,\n",
    "                                 26,\n",
    "                                 13,\n",
    "                                 [1024 for _ in range(2)],\n",
    "                                 [0.5 for _ in range(3)],\n",
    "                                 6).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "checkpoint_dir = os.path.join(cwd, 'DCN_artifact')\n",
    "checkpoint_prefix = 'DCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:20:20 INFO   Epoch 1/5 - Batch 1000/64000 Done - Train Loss: 0.493846, Val Loss: 0.467414\n",
      "01:24:20 INFO   Epoch 1/5 - Batch 2000/64000 Done - Train Loss: 0.482650, Val Loss: 0.459085\n",
      "01:28:20 INFO   Epoch 1/5 - Batch 3000/64000 Done - Train Loss: 0.477697, Val Loss: 0.502537\n",
      "01:32:20 INFO   Epoch 1/5 - Batch 4000/64000 Done - Train Loss: 0.474821, Val Loss: 0.428925\n",
      "01:36:21 INFO   Epoch 1/5 - Batch 5000/64000 Done - Train Loss: 0.472362, Val Loss: 0.468349\n",
      "01:40:21 INFO   Epoch 1/5 - Batch 6000/64000 Done - Train Loss: 0.470290, Val Loss: 0.453534\n",
      "01:44:21 INFO   Epoch 1/5 - Batch 7000/64000 Done - Train Loss: 0.468951, Val Loss: 0.478359\n",
      "01:48:21 INFO   Epoch 1/5 - Batch 8000/64000 Done - Train Loss: 0.467425, Val Loss: 0.444895\n",
      "01:52:21 INFO   Epoch 1/5 - Batch 9000/64000 Done - Train Loss: 0.466191, Val Loss: 0.472482\n",
      "01:56:21 INFO   Epoch 1/5 - Batch 10000/64000 Done - Train Loss: 0.465137, Val Loss: 0.466647\n",
      "02:00:22 INFO   Epoch 1/5 - Batch 11000/64000 Done - Train Loss: 0.464125, Val Loss: 0.460116\n",
      "02:04:22 INFO   Epoch 1/5 - Batch 12000/64000 Done - Train Loss: 0.463252, Val Loss: 0.484666\n",
      "02:08:22 INFO   Epoch 1/5 - Batch 13000/64000 Done - Train Loss: 0.462583, Val Loss: 0.426944\n",
      "02:12:22 INFO   Epoch 1/5 - Batch 14000/64000 Done - Train Loss: 0.462520, Val Loss: 0.437463\n",
      "02:16:22 INFO   Epoch 1/5 - Batch 15000/64000 Done - Train Loss: 0.462472, Val Loss: 0.468400\n",
      "02:20:22 INFO   Epoch 1/5 - Batch 16000/64000 Done - Train Loss: 0.462297, Val Loss: 0.448818\n",
      "02:24:22 INFO   Epoch 1/5 - Batch 17000/64000 Done - Train Loss: 0.462177, Val Loss: 0.475588\n",
      "02:28:22 INFO   Epoch 1/5 - Batch 18000/64000 Done - Train Loss: 0.461965, Val Loss: 0.470784\n",
      "02:32:22 INFO   Epoch 1/5 - Batch 19000/64000 Done - Train Loss: 0.461871, Val Loss: 0.464876\n",
      "02:36:22 INFO   Epoch 1/5 - Batch 20000/64000 Done - Train Loss: 0.461737, Val Loss: 0.490847\n",
      "02:40:21 INFO   Epoch 1/5 - Batch 21000/64000 Done - Train Loss: 0.461624, Val Loss: 0.432727\n",
      "02:44:21 INFO   Epoch 1/5 - Batch 22000/64000 Done - Train Loss: 0.461454, Val Loss: 0.509777\n",
      "02:48:21 INFO   Epoch 1/5 - Batch 23000/64000 Done - Train Loss: 0.461320, Val Loss: 0.475761\n",
      "02:52:21 INFO   Epoch 1/5 - Batch 24000/64000 Done - Train Loss: 0.461189, Val Loss: 0.455504\n",
      "02:56:21 INFO   Epoch 1/5 - Batch 25000/64000 Done - Train Loss: 0.461079, Val Loss: 0.463509\n",
      "03:00:22 INFO   Epoch 1/5 - Batch 26000/64000 Done - Train Loss: 0.460990, Val Loss: 0.445072\n",
      "03:16:21 INFO   Epoch 1/5 - Batch 30000/64000 Done - Train Loss: 0.460726, Val Loss: 0.443203\n",
      "03:20:21 INFO   Epoch 1/5 - Batch 31000/64000 Done - Train Loss: 0.460698, Val Loss: 0.465524\n",
      "03:24:21 INFO   Epoch 1/5 - Batch 32000/64000 Done - Train Loss: 0.460629, Val Loss: 0.409545\n",
      "03:28:21 INFO   Epoch 1/5 - Batch 33000/64000 Done - Train Loss: 0.460480, Val Loss: 0.475451\n",
      "03:32:20 INFO   Epoch 1/5 - Batch 34000/64000 Done - Train Loss: 0.460316, Val Loss: 0.456998\n",
      "03:36:20 INFO   Epoch 1/5 - Batch 35000/64000 Done - Train Loss: 0.460161, Val Loss: 0.472921\n",
      "03:40:20 INFO   Epoch 1/5 - Batch 36000/64000 Done - Train Loss: 0.459979, Val Loss: 0.429074\n",
      "03:44:20 INFO   Epoch 1/5 - Batch 37000/64000 Done - Train Loss: 0.459878, Val Loss: 0.449334\n",
      "03:48:19 INFO   Epoch 1/5 - Batch 38000/64000 Done - Train Loss: 0.459717, Val Loss: 0.452587\n",
      "03:52:19 INFO   Epoch 1/5 - Batch 39000/64000 Done - Train Loss: 0.459629, Val Loss: 0.410658\n",
      "03:56:19 INFO   Epoch 1/5 - Batch 40000/64000 Done - Train Loss: 0.459529, Val Loss: 0.482615\n",
      "04:00:19 INFO   Epoch 1/5 - Batch 41000/64000 Done - Train Loss: 0.459428, Val Loss: 0.457854\n",
      "04:04:18 INFO   Epoch 1/5 - Batch 42000/64000 Done - Train Loss: 0.459302, Val Loss: 0.448095\n",
      "04:08:18 INFO   Epoch 1/5 - Batch 43000/64000 Done - Train Loss: 0.459156, Val Loss: 0.457187\n",
      "04:12:18 INFO   Epoch 1/5 - Batch 44000/64000 Done - Train Loss: 0.459036, Val Loss: 0.466998\n",
      "04:16:18 INFO   Epoch 1/5 - Batch 45000/64000 Done - Train Loss: 0.458926, Val Loss: 0.437895\n",
      "04:20:17 INFO   Epoch 1/5 - Batch 46000/64000 Done - Train Loss: 0.458801, Val Loss: 0.401827\n",
      "04:24:17 INFO   Epoch 1/5 - Batch 47000/64000 Done - Train Loss: 0.458658, Val Loss: 0.466762\n",
      "04:28:17 INFO   Epoch 1/5 - Batch 48000/64000 Done - Train Loss: 0.458524, Val Loss: 0.469100\n",
      "04:32:17 INFO   Epoch 1/5 - Batch 49000/64000 Done - Train Loss: 0.458385, Val Loss: 0.472237\n",
      "04:36:16 INFO   Epoch 1/5 - Batch 50000/64000 Done - Train Loss: 0.458230, Val Loss: 0.502021\n",
      "04:40:16 INFO   Epoch 1/5 - Batch 51000/64000 Done - Train Loss: 0.458099, Val Loss: 0.449258\n",
      "04:44:16 INFO   Epoch 1/5 - Batch 52000/64000 Done - Train Loss: 0.458105, Val Loss: 0.384913\n",
      "04:48:16 INFO   Epoch 1/5 - Batch 53000/64000 Done - Train Loss: 0.458106, Val Loss: 0.432896\n",
      "04:52:16 INFO   Epoch 1/5 - Batch 54000/64000 Done - Train Loss: 0.458085, Val Loss: 0.415688\n",
      "04:56:15 INFO   Epoch 1/5 - Batch 55000/64000 Done - Train Loss: 0.458095, Val Loss: 0.419356\n",
      "05:00:15 INFO   Epoch 1/5 - Batch 56000/64000 Done - Train Loss: 0.458074, Val Loss: 0.504453\n",
      "05:04:15 INFO   Epoch 1/5 - Batch 57000/64000 Done - Train Loss: 0.458045, Val Loss: 0.403335\n",
      "05:08:15 INFO   Epoch 1/5 - Batch 58000/64000 Done - Train Loss: 0.458008, Val Loss: 0.402194\n",
      "05:12:15 INFO   Epoch 1/5 - Batch 59000/64000 Done - Train Loss: 0.457958, Val Loss: 0.417643\n",
      "05:16:14 INFO   Epoch 1/5 - Batch 60000/64000 Done - Train Loss: 0.457900, Val Loss: 0.438480\n",
      "05:20:14 INFO   Epoch 1/5 - Batch 61000/64000 Done - Train Loss: 0.457848, Val Loss: 0.459245\n",
      "05:24:14 INFO   Epoch 1/5 - Batch 62000/64000 Done - Train Loss: 0.457805, Val Loss: 0.437277\n",
      "05:28:14 INFO   Epoch 1/5 - Batch 63000/64000 Done - Train Loss: 0.457736, Val Loss: 0.460168\n"
     ]
    }
   ],
   "source": [
    "execution.train_model_separate_inp(DCN, \n",
    "                                   train_data, \n",
    "                                   train_data, \n",
    "                                   F.binary_cross_entropy_with_logits, \n",
    "                                   torch.optim.Adam(DCN.parameters()), \n",
    "                                   DEVICE, \n",
    "                                   checkpoint_dir, \n",
    "                                   checkpoint_prefix \n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepFM_1', 'DeepFM_2', 'DeepFM_5', 'DeepFM_4', 'DeepFM_3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCN = DCN_BinClf_Torch.DCN_Layer(len(embedding_map_dict)+60,\n",
    "                                 20,\n",
    "                                 26,\n",
    "                                 13,\n",
    "                                 [1024 for _ in range(2)],\n",
    "                                 [0.5 for _ in range(3)],\n",
    "                                 6).to(DEVICE)\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'DCN_2')))\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:29:43 INFO   Model ROC Score: 0.819064\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score_separate_inp(model, train_data, DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:30:42 INFO   Model ROC Score: 0.801416\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score_separate_inp(model, test_data, DEVICE)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
