{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.__version__>='1.2.0', 'Expect PyTorch>=1.2.0 but get {}'.format(torch.__version__)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "imp_dir = '../Implementations'\n",
    "sys.path.insert(1, imp_dir)\n",
    "data_dir = '../Data/criteo'\n",
    "sys.path.insert(1, data_dir)\n",
    "\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)\n",
    "\n",
    "log_path = 'DCN_notebook.log'\n",
    "if os.path.isfile(log_path): os.remove(log_path)\n",
    "    \n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)-s: %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "fh = logging.FileHandler(log_path)\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "sh = logging.StreamHandler(sys.stdout)\n",
    "sh.setLevel(logging.INFO)\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:32:54 INFO: Device in Use: cuda\n",
      "20:32:54 INFO: CUDA Memory: Total 11.17 GB, Cached 0.00 GB, Allocated 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info('Device in Use: {}'.format(DEVICE))\n",
    "torch.cuda.empty_cache()\n",
    "t = torch.cuda.get_device_properties(DEVICE).total_memory/1024**3\n",
    "c = torch.cuda.memory_cached(DEVICE)/1024**3\n",
    "a = torch.cuda.memory_allocated(DEVICE)/1024**3\n",
    "logger.info('CUDA Memory: Total {:.2f} GB, Cached {:.2f} GB, Allocated {:.2f} GB'.format(t,c,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map_dict_pkl_path = os.path.join(data_dir, 'criteo_feature_dict_artifact/categorical_feature_map_dict.pkl')\n",
    "with open(embedding_map_dict_pkl_path, 'rb') as f:\n",
    "    embedding_map_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_artifact_dir = os.path.join(data_dir, 'criteo_train_numpy_artifact')\n",
    "index_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='index', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "value_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='value', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "label_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='label', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:33:32 INFO: Training data loaded after 3634.80s\n",
      "21:33:41 INFO: Test data loaded after 8.91s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[:10]]),\n",
    ")\n",
    "\n",
    "logger.info('Training data loaded after {:.2f}s'.format(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[10:]]),\n",
    ")\n",
    "\n",
    "logger.info('Test data loaded after {:.2f}s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DCN_BinClf_Torch' from '../Implementations/DCN_BinClf_Torch.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import execution\n",
    "import DCN_BinClf_Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCN = DCN_BinClf_Torch.DCN_Layer(len(embedding_map_dict)+60,\n",
    "                                 20,\n",
    "                                 26,\n",
    "                                 13,\n",
    "                                 [1024 for _ in range(2)],\n",
    "                                 [0.5 for _ in range(3)],\n",
    "                                 6).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "checkpoint_dir = os.path.join(cwd, 'DCN_artifact')\n",
    "checkpoint_prefix = 'DCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.train_model_separate_inp(DCN, \n",
    "                                   train_data, \n",
    "                                   test_data, \n",
    "                                   F.binary_cross_entropy_with_logits, \n",
    "                                   torch.optim.Adam(DCN.parameters()), \n",
    "                                   DEVICE, \n",
    "                                   checkpoint_dir, \n",
    "                                   checkpoint_prefix,\n",
    "                                   logger=logger\n",
    "                                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
