{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.__version__>='1.2.0', 'Expect PyTorch>=1.2.0 but get {}'.format(torch.__version__)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "imp_dir = '../Implementations'\n",
    "sys.path.insert(1, imp_dir)\n",
    "data_dir = '../Data/criteo'\n",
    "sys.path.insert(1, data_dir)\n",
    "\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(levelname)-6s %(message)s', level=logging.INFO, datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:53:06 INFO   Device in Use: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info('Device in Use: {}'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_artifact_dir = os.path.join(data_dir, 'criteo_train_numpy_artifact')\n",
    "index_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='index', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "value_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='value', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "label_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='label', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:55:36 INFO   Training data loaded after 148.22s\n",
      "18:55:46 INFO   Test data loaded after 9.45s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[:10]]),\n",
    ")\n",
    "\n",
    "logger.info('Training data loaded after {:.2f}s'.format(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[10:]]),\n",
    ")\n",
    "\n",
    "logger.info('Test data loaded after {:.2f}s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DeepFM_BinClf_Torch' from '../Implementations/DeepFM_BinClf_Torch.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import execution\n",
    "importlib.reload(execution)\n",
    "import DeepFM_BinClf_Torch \n",
    "importlib.reload(DeepFM_BinClf_Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map_dict_pkl_path = os.path.join(data_dir, 'criteo_feature_dict_artifact/categorical_feature_map_dict.pkl')\n",
    "with open(embedding_map_dict_pkl_path, 'rb') as f:\n",
    "    embedding_map_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepFM = DeepFM_BinClf_Torch.DeepFM_2D_Layer(len(embedding_map_dict)+60,\n",
    "                                             39,\n",
    "                                             10, \n",
    "                                             [400 for _ in range(3)], \n",
    "                                             [0, 0], \n",
    "                                             [0.5 for _ in range(4)]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "checkpoint_dir = os.path.join(cwd, 'DeepFM_artifact')\n",
    "checkpoint_prefix = 'DeepFM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:47:54 INFO   Epoch 1/5 - Batch 1000/16000 Done - Train Loss: 0.475276, Val Loss: 0.474818\n",
      "19:48:21 INFO   Epoch 1/5 - Batch 2000/16000 Done - Train Loss: 0.465876, Val Loss: 0.462235\n",
      "19:48:47 INFO   Epoch 1/5 - Batch 3000/16000 Done - Train Loss: 0.461062, Val Loss: 0.458874\n",
      "19:49:13 INFO   Epoch 1/5 - Batch 4000/16000 Done - Train Loss: 0.459669, Val Loss: 0.465313\n",
      "19:49:39 INFO   Epoch 1/5 - Batch 5000/16000 Done - Train Loss: 0.458742, Val Loss: 0.467710\n",
      "19:50:05 INFO   Epoch 1/5 - Batch 6000/16000 Done - Train Loss: 0.457884, Val Loss: 0.461592\n",
      "19:50:31 INFO   Epoch 1/5 - Batch 7000/16000 Done - Train Loss: 0.457315, Val Loss: 0.452011\n",
      "19:50:57 INFO   Epoch 1/5 - Batch 8000/16000 Done - Train Loss: 0.456881, Val Loss: 0.460217\n",
      "19:51:24 INFO   Epoch 1/5 - Batch 9000/16000 Done - Train Loss: 0.456075, Val Loss: 0.453935\n",
      "19:51:50 INFO   Epoch 1/5 - Batch 10000/16000 Done - Train Loss: 0.455462, Val Loss: 0.455011\n",
      "19:52:16 INFO   Epoch 1/5 - Batch 11000/16000 Done - Train Loss: 0.454834, Val Loss: 0.457629\n",
      "19:52:42 INFO   Epoch 1/5 - Batch 12000/16000 Done - Train Loss: 0.454186, Val Loss: 0.450305\n",
      "19:53:08 INFO   Epoch 1/5 - Batch 13000/16000 Done - Train Loss: 0.453636, Val Loss: 0.456892\n",
      "19:53:35 INFO   Epoch 1/5 - Batch 14000/16000 Done - Train Loss: 0.453471, Val Loss: 0.451138\n",
      "19:54:01 INFO   Epoch 1/5 - Batch 15000/16000 Done - Train Loss: 0.453196, Val Loss: 0.449771\n",
      "19:55:20 INFO   Epoch 1/5 - Train Loss: 0.452854, Test Loss: 0.452005, Test ROC Score: 0.801086\n",
      "19:55:48 INFO   Epoch 2/5 - Batch 1000/16000 Done - Train Loss: 0.442350, Val Loss: 0.449903\n",
      "19:56:14 INFO   Epoch 2/5 - Batch 2000/16000 Done - Train Loss: 0.440541, Val Loss: 0.464237\n",
      "19:56:40 INFO   Epoch 2/5 - Batch 3000/16000 Done - Train Loss: 0.439188, Val Loss: 0.446045\n",
      "19:57:07 INFO   Epoch 2/5 - Batch 4000/16000 Done - Train Loss: 0.439789, Val Loss: 0.456006\n",
      "19:57:33 INFO   Epoch 2/5 - Batch 5000/16000 Done - Train Loss: 0.440296, Val Loss: 0.442684\n",
      "19:57:59 INFO   Epoch 2/5 - Batch 6000/16000 Done - Train Loss: 0.440509, Val Loss: 0.451597\n",
      "19:58:25 INFO   Epoch 2/5 - Batch 7000/16000 Done - Train Loss: 0.440789, Val Loss: 0.454045\n",
      "19:58:51 INFO   Epoch 2/5 - Batch 8000/16000 Done - Train Loss: 0.441043, Val Loss: 0.465679\n",
      "19:59:17 INFO   Epoch 2/5 - Batch 9000/16000 Done - Train Loss: 0.440837, Val Loss: 0.452904\n",
      "19:59:44 INFO   Epoch 2/5 - Batch 10000/16000 Done - Train Loss: 0.440706, Val Loss: 0.447015\n",
      "20:00:10 INFO   Epoch 2/5 - Batch 11000/16000 Done - Train Loss: 0.440538, Val Loss: 0.449804\n",
      "20:00:36 INFO   Epoch 2/5 - Batch 12000/16000 Done - Train Loss: 0.440285, Val Loss: 0.459106\n",
      "20:01:02 INFO   Epoch 2/5 - Batch 13000/16000 Done - Train Loss: 0.440110, Val Loss: 0.454775\n",
      "20:01:29 INFO   Epoch 2/5 - Batch 14000/16000 Done - Train Loss: 0.440275, Val Loss: 0.452961\n",
      "20:01:55 INFO   Epoch 2/5 - Batch 15000/16000 Done - Train Loss: 0.440318, Val Loss: 0.448599\n",
      "20:03:21 INFO   Epoch 2/5 - Train Loss: 0.440301, Test Loss: 0.451999, Test ROC Score: 0.801416\n",
      "20:03:49 INFO   Epoch 3/5 - Batch 1000/16000 Done - Train Loss: 0.435642, Val Loss: 0.460862\n",
      "20:04:15 INFO   Epoch 3/5 - Batch 2000/16000 Done - Train Loss: 0.434065, Val Loss: 0.451979\n",
      "20:04:41 INFO   Epoch 3/5 - Batch 3000/16000 Done - Train Loss: 0.432879, Val Loss: 0.449410\n",
      "20:05:07 INFO   Epoch 3/5 - Batch 4000/16000 Done - Train Loss: 0.433544, Val Loss: 0.444470\n",
      "20:05:33 INFO   Epoch 3/5 - Batch 5000/16000 Done - Train Loss: 0.434128, Val Loss: 0.453863\n",
      "20:05:59 INFO   Epoch 3/5 - Batch 6000/16000 Done - Train Loss: 0.434390, Val Loss: 0.459038\n",
      "20:06:26 INFO   Epoch 3/5 - Batch 7000/16000 Done - Train Loss: 0.434724, Val Loss: 0.447983\n",
      "20:06:52 INFO   Epoch 3/5 - Batch 8000/16000 Done - Train Loss: 0.435030, Val Loss: 0.459457\n",
      "20:07:18 INFO   Epoch 3/5 - Batch 9000/16000 Done - Train Loss: 0.434885, Val Loss: 0.446547\n",
      "20:07:44 INFO   Epoch 3/5 - Batch 10000/16000 Done - Train Loss: 0.434803, Val Loss: 0.443575\n",
      "20:08:11 INFO   Epoch 3/5 - Batch 11000/16000 Done - Train Loss: 0.434700, Val Loss: 0.456036\n",
      "20:08:37 INFO   Epoch 3/5 - Batch 12000/16000 Done - Train Loss: 0.434498, Val Loss: 0.459576\n",
      "20:09:03 INFO   Epoch 3/5 - Batch 13000/16000 Done - Train Loss: 0.434381, Val Loss: 0.449656\n",
      "20:09:29 INFO   Epoch 3/5 - Batch 14000/16000 Done - Train Loss: 0.434591, Val Loss: 0.451432\n",
      "20:09:55 INFO   Epoch 3/5 - Batch 15000/16000 Done - Train Loss: 0.434686, Val Loss: 0.441699\n",
      "20:11:21 INFO   Epoch 3/5 - Train Loss: 0.434731, Test Loss: 0.453646, Test ROC Score: 0.800164\n",
      "20:11:48 INFO   Epoch 4/5 - Batch 1000/16000 Done - Train Loss: 0.431293, Val Loss: 0.462571\n",
      "20:12:14 INFO   Epoch 4/5 - Batch 2000/16000 Done - Train Loss: 0.429900, Val Loss: 0.451428\n",
      "20:12:40 INFO   Epoch 4/5 - Batch 3000/16000 Done - Train Loss: 0.428855, Val Loss: 0.447603\n",
      "20:13:07 INFO   Epoch 4/5 - Batch 4000/16000 Done - Train Loss: 0.429529, Val Loss: 0.464459\n",
      "20:13:33 INFO   Epoch 4/5 - Batch 5000/16000 Done - Train Loss: 0.430160, Val Loss: 0.452857\n",
      "20:13:59 INFO   Epoch 4/5 - Batch 6000/16000 Done - Train Loss: 0.430464, Val Loss: 0.457425\n",
      "20:14:25 INFO   Epoch 4/5 - Batch 7000/16000 Done - Train Loss: 0.430834, Val Loss: 0.455417\n",
      "20:14:51 INFO   Epoch 4/5 - Batch 8000/16000 Done - Train Loss: 0.431197, Val Loss: 0.466762\n",
      "20:15:17 INFO   Epoch 4/5 - Batch 9000/16000 Done - Train Loss: 0.431091, Val Loss: 0.453166\n",
      "20:15:43 INFO   Epoch 4/5 - Batch 10000/16000 Done - Train Loss: 0.431045, Val Loss: 0.456363\n",
      "20:16:10 INFO   Epoch 4/5 - Batch 11000/16000 Done - Train Loss: 0.430968, Val Loss: 0.457059\n",
      "20:16:36 INFO   Epoch 4/5 - Batch 12000/16000 Done - Train Loss: 0.430785, Val Loss: 0.465982\n",
      "20:17:02 INFO   Epoch 4/5 - Batch 13000/16000 Done - Train Loss: 0.430687, Val Loss: 0.444000\n",
      "20:17:28 INFO   Epoch 4/5 - Batch 14000/16000 Done - Train Loss: 0.430907, Val Loss: 0.449818\n",
      "20:17:54 INFO   Epoch 4/5 - Batch 15000/16000 Done - Train Loss: 0.431023, Val Loss: 0.454186\n",
      "20:19:19 INFO   Epoch 4/5 - Train Loss: 0.431100, Test Loss: 0.455589, Test ROC Score: 0.798672\n",
      "20:19:46 INFO   Epoch 5/5 - Batch 1000/16000 Done - Train Loss: 0.428135, Val Loss: 0.458652\n",
      "20:20:12 INFO   Epoch 5/5 - Batch 2000/16000 Done - Train Loss: 0.426859, Val Loss: 0.455556\n",
      "20:20:38 INFO   Epoch 5/5 - Batch 3000/16000 Done - Train Loss: 0.425901, Val Loss: 0.452972\n",
      "20:21:04 INFO   Epoch 5/5 - Batch 4000/16000 Done - Train Loss: 0.426622, Val Loss: 0.463700\n",
      "20:21:30 INFO   Epoch 5/5 - Batch 5000/16000 Done - Train Loss: 0.427306, Val Loss: 0.454918\n",
      "20:21:55 INFO   Epoch 5/5 - Batch 6000/16000 Done - Train Loss: 0.427656, Val Loss: 0.455541\n",
      "20:22:21 INFO   Epoch 5/5 - Batch 7000/16000 Done - Train Loss: 0.428054, Val Loss: 0.468279\n",
      "20:22:47 INFO   Epoch 5/5 - Batch 8000/16000 Done - Train Loss: 0.428436, Val Loss: 0.454535\n",
      "20:23:13 INFO   Epoch 5/5 - Batch 9000/16000 Done - Train Loss: 0.428360, Val Loss: 0.465227\n",
      "20:23:39 INFO   Epoch 5/5 - Batch 10000/16000 Done - Train Loss: 0.428320, Val Loss: 0.456507\n",
      "20:24:05 INFO   Epoch 5/5 - Batch 11000/16000 Done - Train Loss: 0.428261, Val Loss: 0.451749\n",
      "20:24:31 INFO   Epoch 5/5 - Batch 12000/16000 Done - Train Loss: 0.428090, Val Loss: 0.457078\n",
      "20:24:57 INFO   Epoch 5/5 - Batch 13000/16000 Done - Train Loss: 0.428007, Val Loss: 0.458429\n",
      "20:25:22 INFO   Epoch 5/5 - Batch 14000/16000 Done - Train Loss: 0.428239, Val Loss: 0.458808\n",
      "20:25:48 INFO   Epoch 5/5 - Batch 15000/16000 Done - Train Loss: 0.428362, Val Loss: 0.460627\n",
      "20:27:14 INFO   Epoch 5/5 - Train Loss: 0.428454, Test Loss: 0.457336, Test ROC Score: 0.797329\n"
     ]
    }
   ],
   "source": [
    "execution.train_model(DeepFM, \n",
    "                      train_data, \n",
    "                      test_data, \n",
    "                      F.binary_cross_entropy_with_logits, \n",
    "                      torch.optim.Adam(DeepFM.parameters()), \n",
    "                      DEVICE, \n",
    "                      checkpoint_dir, \n",
    "                      checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepFM_1', 'DeepFM_2', 'DeepFM_5', 'DeepFM_4', 'DeepFM_3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM_BinClf_Torch.DeepFM_2D_Layer(len(embedding_map_dict)+60,\n",
    "                                             39,\n",
    "                                             10, \n",
    "                                             [400 for _ in range(3)], \n",
    "                                             [0, 0], \n",
    "                                             [0.5 for _ in range(4)]).to(DEVICE)\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'DeepFM_2')))\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:29:43 INFO   Model ROC Score: 0.819064\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score(model, train_data, DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:30:42 INFO   Model ROC Score: 0.801416\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score(model, test_data, DEVICE)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
