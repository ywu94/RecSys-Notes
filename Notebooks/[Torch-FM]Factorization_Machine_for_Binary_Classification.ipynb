{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.__version__>='1.2.0', 'Expect PyTorch>=1.2.0 but get {}'.format(torch.__version__)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "imp_dir = '../Implementations'\n",
    "sys.path.insert(1, imp_dir)\n",
    "data_dir = '../Data/criteo'\n",
    "sys.path.insert(1, data_dir)\n",
    "\n",
    "from FM_BinClf_Torch import FM_2D_Layer\n",
    "\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(levelname)-6s %(message)s', level=logging.INFO, datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:25:43 INFO   Device in Use: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info('Device in Use: {}'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_artifact_dir = os.path.join(data_dir, 'criteo_train_numpy_artifact')\n",
    "index_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='index', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "value_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='value', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "label_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='label', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:26:03 INFO   Training data loaded after 20.07s\n",
      "00:26:30 INFO   Test data loaded after 26.78s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[:10]]),\n",
    ")\n",
    "\n",
    "logger.info('Training data loaded after {:.2f}s'.format(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[10:]]),\n",
    ")\n",
    "\n",
    "logger.info('Test data loaded after {:.2f}s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map_dict_pkl_path = os.path.join(data_dir, 'criteo_feature_dict_artifact/categorical_feature_map_dict.pkl')\n",
    "with open(embedding_map_dict_pkl_path, 'rb') as f:\n",
    "    embedding_map_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM = FM_2D_Layer(len(embedding_map_dict)+60,39,5).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'execution' from '../Data/criteo/execution.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import execution\n",
    "importlib.reload(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "checkpoint_dir = os.path.join(cwd, 'FM_artifact')\n",
    "checkpoint_prefix = 'FM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:31:11 INFO   Epoch 1/5 - Batch 1000/16000 Done - Train Loss: 0.467114, Val Loss: 0.474068\n",
      "00:31:21 INFO   Epoch 1/5 - Batch 2000/16000 Done - Train Loss: 0.461353, Val Loss: 0.463995\n",
      "00:31:30 INFO   Epoch 1/5 - Batch 3000/16000 Done - Train Loss: 0.458274, Val Loss: 0.466305\n",
      "00:31:40 INFO   Epoch 1/5 - Batch 4000/16000 Done - Train Loss: 0.458031, Val Loss: 0.463272\n",
      "00:31:49 INFO   Epoch 1/5 - Batch 5000/16000 Done - Train Loss: 0.457944, Val Loss: 0.471607\n",
      "00:31:59 INFO   Epoch 1/5 - Batch 6000/16000 Done - Train Loss: 0.457793, Val Loss: 0.458427\n",
      "00:32:08 INFO   Epoch 1/5 - Batch 7000/16000 Done - Train Loss: 0.457810, Val Loss: 0.466020\n",
      "00:32:17 INFO   Epoch 1/5 - Batch 8000/16000 Done - Train Loss: 0.457837, Val Loss: 0.450748\n",
      "00:32:27 INFO   Epoch 1/5 - Batch 9000/16000 Done - Train Loss: 0.457430, Val Loss: 0.452050\n",
      "00:32:36 INFO   Epoch 1/5 - Batch 10000/16000 Done - Train Loss: 0.457175, Val Loss: 0.463292\n",
      "00:32:46 INFO   Epoch 1/5 - Batch 11000/16000 Done - Train Loss: 0.456863, Val Loss: 0.467955\n",
      "00:32:56 INFO   Epoch 1/5 - Batch 12000/16000 Done - Train Loss: 0.456526, Val Loss: 0.456952\n",
      "00:33:05 INFO   Epoch 1/5 - Batch 13000/16000 Done - Train Loss: 0.456233, Val Loss: 0.462937\n",
      "00:33:15 INFO   Epoch 1/5 - Batch 14000/16000 Done - Train Loss: 0.456319, Val Loss: 0.468240\n",
      "00:33:24 INFO   Epoch 1/5 - Batch 15000/16000 Done - Train Loss: 0.456286, Val Loss: 0.455838\n",
      "00:34:09 INFO   Epoch 1/5 - Train Loss: 0.456159, Test Loss: 0.459659, Test ROC Score: 0.792765\n",
      "00:34:19 INFO   Epoch 2/5 - Batch 1000/16000 Done - Train Loss: 0.447870, Val Loss: 0.461864\n",
      "00:34:28 INFO   Epoch 2/5 - Batch 2000/16000 Done - Train Loss: 0.445998, Val Loss: 0.454719\n",
      "00:34:38 INFO   Epoch 2/5 - Batch 3000/16000 Done - Train Loss: 0.444764, Val Loss: 0.457533\n",
      "00:34:47 INFO   Epoch 2/5 - Batch 4000/16000 Done - Train Loss: 0.445567, Val Loss: 0.464170\n",
      "00:34:57 INFO   Epoch 2/5 - Batch 5000/16000 Done - Train Loss: 0.446307, Val Loss: 0.459525\n",
      "00:35:06 INFO   Epoch 2/5 - Batch 6000/16000 Done - Train Loss: 0.446801, Val Loss: 0.460342\n",
      "00:35:16 INFO   Epoch 2/5 - Batch 7000/16000 Done - Train Loss: 0.447329, Val Loss: 0.464175\n",
      "00:35:25 INFO   Epoch 2/5 - Batch 8000/16000 Done - Train Loss: 0.447806, Val Loss: 0.458037\n",
      "00:35:34 INFO   Epoch 2/5 - Batch 9000/16000 Done - Train Loss: 0.447774, Val Loss: 0.468744\n",
      "00:35:44 INFO   Epoch 2/5 - Batch 10000/16000 Done - Train Loss: 0.447812, Val Loss: 0.462823\n",
      "00:35:53 INFO   Epoch 2/5 - Batch 11000/16000 Done - Train Loss: 0.447788, Val Loss: 0.462823\n",
      "00:36:03 INFO   Epoch 2/5 - Batch 12000/16000 Done - Train Loss: 0.447692, Val Loss: 0.466973\n",
      "00:36:12 INFO   Epoch 2/5 - Batch 13000/16000 Done - Train Loss: 0.447619, Val Loss: 0.459194\n",
      "00:36:22 INFO   Epoch 2/5 - Batch 14000/16000 Done - Train Loss: 0.447904, Val Loss: 0.466374\n",
      "00:36:31 INFO   Epoch 2/5 - Batch 15000/16000 Done - Train Loss: 0.448064, Val Loss: 0.471858\n",
      "00:37:18 INFO   Epoch 2/5 - Train Loss: 0.448132, Test Loss: 0.463276, Test ROC Score: 0.790271\n",
      "00:37:28 INFO   Epoch 3/5 - Batch 1000/16000 Done - Train Loss: 0.443948, Val Loss: 0.465842\n",
      "00:37:37 INFO   Epoch 3/5 - Batch 2000/16000 Done - Train Loss: 0.442476, Val Loss: 0.469843\n",
      "00:37:47 INFO   Epoch 3/5 - Batch 3000/16000 Done - Train Loss: 0.441551, Val Loss: 0.460914\n",
      "00:37:56 INFO   Epoch 3/5 - Batch 4000/16000 Done - Train Loss: 0.442512, Val Loss: 0.474285\n",
      "00:38:06 INFO   Epoch 3/5 - Batch 5000/16000 Done - Train Loss: 0.443382, Val Loss: 0.475455\n",
      "00:38:15 INFO   Epoch 3/5 - Batch 6000/16000 Done - Train Loss: 0.443964, Val Loss: 0.464669\n",
      "00:38:25 INFO   Epoch 3/5 - Batch 7000/16000 Done - Train Loss: 0.444557, Val Loss: 0.476629\n",
      "00:38:34 INFO   Epoch 3/5 - Batch 8000/16000 Done - Train Loss: 0.445093, Val Loss: 0.457174\n",
      "00:38:44 INFO   Epoch 3/5 - Batch 9000/16000 Done - Train Loss: 0.445104, Val Loss: 0.462103\n",
      "00:38:53 INFO   Epoch 3/5 - Batch 10000/16000 Done - Train Loss: 0.445166, Val Loss: 0.471141\n",
      "00:39:03 INFO   Epoch 3/5 - Batch 11000/16000 Done - Train Loss: 0.445174, Val Loss: 0.460044\n",
      "00:39:12 INFO   Epoch 3/5 - Batch 12000/16000 Done - Train Loss: 0.445090, Val Loss: 0.459407\n",
      "00:39:22 INFO   Epoch 3/5 - Batch 13000/16000 Done - Train Loss: 0.445032, Val Loss: 0.473163\n",
      "00:39:31 INFO   Epoch 3/5 - Batch 14000/16000 Done - Train Loss: 0.445330, Val Loss: 0.466655\n",
      "00:39:41 INFO   Epoch 3/5 - Batch 15000/16000 Done - Train Loss: 0.445506, Val Loss: 0.461301\n",
      "00:40:28 INFO   Epoch 3/5 - Train Loss: 0.445596, Test Loss: 0.467591, Test ROC Score: 0.787371\n",
      "00:40:38 INFO   Epoch 4/5 - Batch 1000/16000 Done - Train Loss: 0.442118, Val Loss: 0.462537\n",
      "00:40:47 INFO   Epoch 4/5 - Batch 2000/16000 Done - Train Loss: 0.440829, Val Loss: 0.469980\n",
      "00:40:57 INFO   Epoch 4/5 - Batch 3000/16000 Done - Train Loss: 0.440057, Val Loss: 0.469858\n",
      "00:41:06 INFO   Epoch 4/5 - Batch 4000/16000 Done - Train Loss: 0.441094, Val Loss: 0.468575\n",
      "00:41:16 INFO   Epoch 4/5 - Batch 5000/16000 Done - Train Loss: 0.442025, Val Loss: 0.473099\n",
      "00:41:25 INFO   Epoch 4/5 - Batch 6000/16000 Done - Train Loss: 0.442644, Val Loss: 0.477449\n",
      "00:41:35 INFO   Epoch 4/5 - Batch 7000/16000 Done - Train Loss: 0.443260, Val Loss: 0.480822\n",
      "00:41:44 INFO   Epoch 4/5 - Batch 8000/16000 Done - Train Loss: 0.443822, Val Loss: 0.470911\n",
      "00:41:53 INFO   Epoch 4/5 - Batch 9000/16000 Done - Train Loss: 0.443846, Val Loss: 0.464529\n",
      "00:42:03 INFO   Epoch 4/5 - Batch 10000/16000 Done - Train Loss: 0.443909, Val Loss: 0.481000\n",
      "00:42:12 INFO   Epoch 4/5 - Batch 11000/16000 Done - Train Loss: 0.443924, Val Loss: 0.473869\n",
      "00:42:22 INFO   Epoch 4/5 - Batch 12000/16000 Done - Train Loss: 0.443835, Val Loss: 0.471917\n",
      "00:42:32 INFO   Epoch 4/5 - Batch 13000/16000 Done - Train Loss: 0.443774, Val Loss: 0.465033\n",
      "00:42:41 INFO   Epoch 4/5 - Batch 14000/16000 Done - Train Loss: 0.444070, Val Loss: 0.473138\n",
      "00:42:51 INFO   Epoch 4/5 - Batch 15000/16000 Done - Train Loss: 0.444247, Val Loss: 0.470708\n",
      "00:43:38 INFO   Epoch 4/5 - Train Loss: 0.444341, Test Loss: 0.471943, Test ROC Score: 0.784600\n",
      "00:43:48 INFO   Epoch 5/5 - Batch 1000/16000 Done - Train Loss: 0.441101, Val Loss: 0.469025\n",
      "00:43:57 INFO   Epoch 5/5 - Batch 2000/16000 Done - Train Loss: 0.439932, Val Loss: 0.471007\n",
      "00:44:07 INFO   Epoch 5/5 - Batch 3000/16000 Done - Train Loss: 0.439249, Val Loss: 0.475921\n",
      "00:44:16 INFO   Epoch 5/5 - Batch 4000/16000 Done - Train Loss: 0.440329, Val Loss: 0.473981\n",
      "00:44:26 INFO   Epoch 5/5 - Batch 5000/16000 Done - Train Loss: 0.441295, Val Loss: 0.469581\n",
      "00:44:35 INFO   Epoch 5/5 - Batch 6000/16000 Done - Train Loss: 0.441933, Val Loss: 0.494514\n",
      "00:44:45 INFO   Epoch 5/5 - Batch 7000/16000 Done - Train Loss: 0.442558, Val Loss: 0.475119\n",
      "00:44:54 INFO   Epoch 5/5 - Batch 8000/16000 Done - Train Loss: 0.443134, Val Loss: 0.484475\n",
      "00:45:04 INFO   Epoch 5/5 - Batch 9000/16000 Done - Train Loss: 0.443164, Val Loss: 0.478596\n",
      "00:45:13 INFO   Epoch 5/5 - Batch 10000/16000 Done - Train Loss: 0.443224, Val Loss: 0.474454\n",
      "00:45:23 INFO   Epoch 5/5 - Batch 11000/16000 Done - Train Loss: 0.443238, Val Loss: 0.476657\n",
      "00:45:32 INFO   Epoch 5/5 - Batch 12000/16000 Done - Train Loss: 0.443141, Val Loss: 0.479058\n",
      "00:45:42 INFO   Epoch 5/5 - Batch 13000/16000 Done - Train Loss: 0.443076, Val Loss: 0.480147\n",
      "00:45:51 INFO   Epoch 5/5 - Batch 14000/16000 Done - Train Loss: 0.443366, Val Loss: 0.472813\n",
      "00:46:01 INFO   Epoch 5/5 - Batch 15000/16000 Done - Train Loss: 0.443541, Val Loss: 0.476473\n",
      "00:46:48 INFO   Epoch 5/5 - Train Loss: 0.443636, Test Loss: 0.476308, Test ROC Score: 0.781985\n"
     ]
    }
   ],
   "source": [
    "execution.train_model(FM, train_data, test_data, F.binary_cross_entropy_with_logits, torch.optim.Adam(FM.parameters()), DEVICE, checkpoint_dir, checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FM_4', 'FM_1', 'FM_5', 'FM_2', 'FM_3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FM_2D_Layer(len(embedding_map_dict)+60,39,5)\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'FM_1')))\n",
    "model.eval()\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:49:15 INFO   Model ROC Score: 0.805470\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score(model, train_data, DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:49:53 INFO   Model ROC Score: 0.792765\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score(model, test_data, DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FM_2D_Layer(len(embedding_map_dict)+60,39,5)\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'FM_5')))\n",
    "model.eval()\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:51:26 INFO   Model ROC Score: 0.813573\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score(model, train_data, DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:52:03 INFO   Model ROC Score: 0.781985\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score(model, test_data, DEVICE)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
