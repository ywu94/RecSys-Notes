{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.__version__>='1.2.0', 'Expect PyTorch>=1.2.0 but get {}'.format(torch.__version__)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "imp_dir = '../Implementations'\n",
    "sys.path.insert(1, imp_dir)\n",
    "data_dir = '../Data/criteo'\n",
    "sys.path.insert(1, data_dir)\n",
    "\n",
    "from FM_BinClf_Torch import FM_2D_Layer\n",
    "\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(levelname)-6s %(message)s', level=logging.INFO, datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:08:35 INFO   cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM = FM_2D_Layer(len(embedding_map_dict)+52,39,10).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'execution' from '../Data/criteo/execution.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import execution\n",
    "importlib.reload(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04:48:18 INFO   Total Epoch: 1/5, Current File Progress: 1/1\n",
      "04:48:18 INFO   Processing ../Data/criteo/criteo_train_raw_artifact/train-part-0\n",
      "04:50:35 INFO   -    Batch 100/1600 Done, Training Loss: 0.289107\n",
      "04:50:36 INFO   -    Batch 200/1600 Done, Training Loss: 0.290812\n",
      "04:50:37 INFO   -    Batch 300/1600 Done, Training Loss: 0.292579\n",
      "04:50:39 INFO   -    Batch 400/1600 Done, Training Loss: 0.293960\n",
      "04:50:40 INFO   -    Batch 500/1600 Done, Training Loss: 0.295112\n",
      "04:50:42 INFO   -    Batch 600/1600 Done, Training Loss: 0.296578\n",
      "04:50:43 INFO   -    Batch 700/1600 Done, Training Loss: 0.297880\n",
      "04:50:44 INFO   -    Batch 800/1600 Done, Training Loss: 0.298626\n",
      "04:50:46 INFO   -    Batch 900/1600 Done, Training Loss: 0.299549\n",
      "04:50:47 INFO   -    Batch 1000/1600 Done, Training Loss: 0.300349\n",
      "04:50:49 INFO   -    Batch 1100/1600 Done, Training Loss: 0.301343\n",
      "04:50:50 INFO   -    Batch 1200/1600 Done, Training Loss: 0.302104\n",
      "04:50:51 INFO   -    Batch 1300/1600 Done, Training Loss: 0.302821\n",
      "04:50:53 INFO   -    Batch 1400/1600 Done, Training Loss: 0.303444\n",
      "04:50:54 INFO   -    Batch 1500/1600 Done, Training Loss: 0.304073\n",
      "04:50:55 INFO   -    Batch 1600/1600 Done, Training Loss: 0.304829\n",
      "04:50:56 INFO   Total Epoch: 2/5, Current File Progress: 1/1\n",
      "04:50:56 INFO   Processing ../Data/criteo/criteo_train_raw_artifact/train-part-0\n",
      "04:53:08 INFO   -    Batch 100/1600 Done, Training Loss: 0.290600\n",
      "04:53:09 INFO   -    Batch 200/1600 Done, Training Loss: 0.290917\n",
      "04:53:11 INFO   -    Batch 300/1600 Done, Training Loss: 0.291924\n",
      "04:53:12 INFO   -    Batch 400/1600 Done, Training Loss: 0.292321\n",
      "04:53:13 INFO   -    Batch 500/1600 Done, Training Loss: 0.294047\n",
      "04:53:15 INFO   -    Batch 600/1600 Done, Training Loss: 0.295155\n",
      "04:53:16 INFO   -    Batch 700/1600 Done, Training Loss: 0.296458\n",
      "04:53:18 INFO   -    Batch 800/1600 Done, Training Loss: 0.297186\n",
      "04:53:19 INFO   -    Batch 900/1600 Done, Training Loss: 0.298185\n",
      "04:53:20 INFO   -    Batch 1000/1600 Done, Training Loss: 0.299171\n",
      "04:53:22 INFO   -    Batch 1100/1600 Done, Training Loss: 0.300106\n",
      "04:53:23 INFO   -    Batch 1200/1600 Done, Training Loss: 0.301007\n",
      "04:53:24 INFO   -    Batch 1300/1600 Done, Training Loss: 0.301739\n",
      "04:53:26 INFO   -    Batch 1400/1600 Done, Training Loss: 0.302519\n",
      "04:53:27 INFO   -    Batch 1500/1600 Done, Training Loss: 0.303222\n",
      "04:53:29 INFO   -    Batch 1600/1600 Done, Training Loss: 0.303959\n",
      "04:53:29 INFO   Total Epoch: 3/5, Current File Progress: 1/1\n",
      "04:53:29 INFO   Processing ../Data/criteo/criteo_train_raw_artifact/train-part-0\n",
      "04:55:43 INFO   -    Batch 100/1600 Done, Training Loss: 0.286289\n",
      "04:55:44 INFO   -    Batch 200/1600 Done, Training Loss: 0.288331\n",
      "04:55:45 INFO   -    Batch 300/1600 Done, Training Loss: 0.290690\n",
      "04:55:47 INFO   -    Batch 400/1600 Done, Training Loss: 0.291056\n",
      "04:55:48 INFO   -    Batch 500/1600 Done, Training Loss: 0.292555\n",
      "04:55:49 INFO   -    Batch 600/1600 Done, Training Loss: 0.293932\n",
      "04:55:51 INFO   -    Batch 700/1600 Done, Training Loss: 0.294895\n",
      "04:55:52 INFO   -    Batch 800/1600 Done, Training Loss: 0.295925\n",
      "04:55:53 INFO   -    Batch 900/1600 Done, Training Loss: 0.297064\n",
      "04:55:55 INFO   -    Batch 1000/1600 Done, Training Loss: 0.297991\n",
      "04:55:56 INFO   -    Batch 1100/1600 Done, Training Loss: 0.298824\n",
      "04:55:58 INFO   -    Batch 1200/1600 Done, Training Loss: 0.299663\n",
      "04:55:59 INFO   -    Batch 1300/1600 Done, Training Loss: 0.300543\n",
      "04:56:00 INFO   -    Batch 1400/1600 Done, Training Loss: 0.301400\n",
      "04:56:02 INFO   -    Batch 1500/1600 Done, Training Loss: 0.302151\n",
      "04:56:03 INFO   -    Batch 1600/1600 Done, Training Loss: 0.302847\n",
      "04:56:03 INFO   Total Epoch: 4/5, Current File Progress: 1/1\n",
      "04:56:03 INFO   Processing ../Data/criteo/criteo_train_raw_artifact/train-part-0\n",
      "04:58:17 INFO   -    Batch 100/1600 Done, Training Loss: 0.288284\n",
      "04:58:18 INFO   -    Batch 200/1600 Done, Training Loss: 0.289193\n",
      "04:58:19 INFO   -    Batch 300/1600 Done, Training Loss: 0.289947\n",
      "04:58:21 INFO   -    Batch 400/1600 Done, Training Loss: 0.291382\n",
      "04:58:22 INFO   -    Batch 500/1600 Done, Training Loss: 0.292995\n",
      "04:58:23 INFO   -    Batch 600/1600 Done, Training Loss: 0.293715\n",
      "04:58:25 INFO   -    Batch 700/1600 Done, Training Loss: 0.294590\n",
      "04:58:26 INFO   -    Batch 800/1600 Done, Training Loss: 0.295570\n",
      "04:58:28 INFO   -    Batch 900/1600 Done, Training Loss: 0.296569\n",
      "04:58:29 INFO   -    Batch 1000/1600 Done, Training Loss: 0.297406\n",
      "04:58:30 INFO   -    Batch 1100/1600 Done, Training Loss: 0.298208\n",
      "04:58:32 INFO   -    Batch 1200/1600 Done, Training Loss: 0.299012\n",
      "04:58:33 INFO   -    Batch 1300/1600 Done, Training Loss: 0.299901\n",
      "04:58:34 INFO   -    Batch 1400/1600 Done, Training Loss: 0.300617\n",
      "04:58:36 INFO   -    Batch 1500/1600 Done, Training Loss: 0.301329\n",
      "04:58:37 INFO   -    Batch 1600/1600 Done, Training Loss: 0.302104\n",
      "04:58:37 INFO   Total Epoch: 5/5, Current File Progress: 1/1\n",
      "04:58:37 INFO   Processing ../Data/criteo/criteo_train_raw_artifact/train-part-0\n",
      "05:00:49 INFO   -    Batch 100/1600 Done, Training Loss: 0.288024\n",
      "05:00:51 INFO   -    Batch 200/1600 Done, Training Loss: 0.287783\n",
      "05:00:52 INFO   -    Batch 300/1600 Done, Training Loss: 0.288709\n",
      "05:00:54 INFO   -    Batch 400/1600 Done, Training Loss: 0.289617\n",
      "05:00:55 INFO   -    Batch 500/1600 Done, Training Loss: 0.291228\n",
      "05:00:56 INFO   -    Batch 600/1600 Done, Training Loss: 0.292705\n",
      "05:00:58 INFO   -    Batch 700/1600 Done, Training Loss: 0.293697\n",
      "05:00:59 INFO   -    Batch 800/1600 Done, Training Loss: 0.294821\n",
      "05:01:00 INFO   -    Batch 900/1600 Done, Training Loss: 0.295911\n",
      "05:01:02 INFO   -    Batch 1000/1600 Done, Training Loss: 0.296655\n",
      "05:01:03 INFO   -    Batch 1100/1600 Done, Training Loss: 0.297356\n",
      "05:01:05 INFO   -    Batch 1200/1600 Done, Training Loss: 0.298299\n",
      "05:01:06 INFO   -    Batch 1300/1600 Done, Training Loss: 0.299201\n",
      "05:01:07 INFO   -    Batch 1400/1600 Done, Training Loss: 0.299832\n",
      "05:01:09 INFO   -    Batch 1500/1600 Done, Training Loss: 0.300600\n",
      "05:01:10 INFO   -    Batch 1600/1600 Done, Training Loss: 0.301294\n"
     ]
    }
   ],
   "source": [
    "for i in range(execution.EPOCHES):\n",
    "    execution.train_model(\n",
    "        i+1, \n",
    "        FM, \n",
    "        ['../Data/criteo/criteo_train_raw_artifact/train-part-0'],\n",
    "        #sorted(train_file_list, key = lambda x:int(x.split('-')[-1])), \n",
    "        embedding_map_dict, \n",
    "        F.binary_cross_entropy_with_logits, \n",
    "        torch.optim.Adam(FM.parameters()), \n",
    "        DEVICE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
