{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.__version__>='1.2.0', 'Expect PyTorch>=1.2.0 but get {}'.format(torch.__version__)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "imp_dir = '../Implementations'\n",
    "sys.path.insert(1, imp_dir)\n",
    "data_dir = '../Data/criteo'\n",
    "sys.path.insert(1, data_dir)\n",
    "\n",
    "from FM_BinClf_Torch import FM_2D_Layer\n",
    "\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(levelname)-6s %(message)s', level=logging.INFO, datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:18:49 INFO   Device in Use: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info('Device in Use: {}'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_artifact_dir = os.path.join(data_dir, 'criteo_train_numpy_artifact')\n",
    "index_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='index', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "value_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='value', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "label_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='label', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:26:58 INFO   Training data loaded after 4088.81s\n",
      "17:52:11 INFO   Test data loaded after 1512.96s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[:10]]),\n",
    ")\n",
    "\n",
    "logger.info('Training data loaded after {:.2f}s'.format(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[10:]]),\n",
    ")\n",
    "\n",
    "logger.info('Test data loaded after {:.2f}s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map_dict_pkl_path = os.path.join(data_dir, 'criteo_feature_dict_artifact/categorical_feature_map_dict.pkl')\n",
    "with open(embedding_map_dict_pkl_path, 'rb') as f:\n",
    "    embedding_map_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM = FM_2D_Layer(len(embedding_map_dict)+60,39,5).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'execution' from '../Data/criteo/execution.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import execution\n",
    "importlib.reload(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "checkpoint_dir = os.path.join(cwd, 'FM_artifact')\n",
    "checkpoint_prefix = 'FM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:52:54 INFO   Epoch 1/5 - Batch 1000/16000 Done - Train Loss: 0.466783, Val Loss: 0.458799\n",
      "17:53:03 INFO   Epoch 1/5 - Batch 2000/16000 Done - Train Loss: 0.461234, Val Loss: 0.464833\n",
      "17:53:13 INFO   Epoch 1/5 - Batch 3000/16000 Done - Train Loss: 0.458245, Val Loss: 0.454681\n",
      "17:53:23 INFO   Epoch 1/5 - Batch 4000/16000 Done - Train Loss: 0.458022, Val Loss: 0.458335\n",
      "17:53:32 INFO   Epoch 1/5 - Batch 5000/16000 Done - Train Loss: 0.457959, Val Loss: 0.461044\n",
      "17:53:42 INFO   Epoch 1/5 - Batch 6000/16000 Done - Train Loss: 0.457823, Val Loss: 0.472640\n",
      "17:53:52 INFO   Epoch 1/5 - Batch 7000/16000 Done - Train Loss: 0.457852, Val Loss: 0.465482\n",
      "17:54:01 INFO   Epoch 1/5 - Batch 8000/16000 Done - Train Loss: 0.457886, Val Loss: 0.465019\n",
      "17:54:11 INFO   Epoch 1/5 - Batch 9000/16000 Done - Train Loss: 0.457489, Val Loss: 0.462517\n",
      "17:54:21 INFO   Epoch 1/5 - Batch 10000/16000 Done - Train Loss: 0.457241, Val Loss: 0.472444\n",
      "17:54:30 INFO   Epoch 1/5 - Batch 11000/16000 Done - Train Loss: 0.456933, Val Loss: 0.462394\n",
      "17:54:40 INFO   Epoch 1/5 - Batch 12000/16000 Done - Train Loss: 0.456599, Val Loss: 0.451241\n",
      "17:54:50 INFO   Epoch 1/5 - Batch 13000/16000 Done - Train Loss: 0.456307, Val Loss: 0.468566\n",
      "17:54:59 INFO   Epoch 1/5 - Batch 14000/16000 Done - Train Loss: 0.456397, Val Loss: 0.464205\n",
      "17:55:09 INFO   Epoch 1/5 - Batch 15000/16000 Done - Train Loss: 0.456368, Val Loss: 0.464229\n",
      "17:55:58 INFO   Epoch 1/5 - Train Loss: 0.456242, Test Loss: 0.459898, Test ROC Score: 0.792564\n",
      "17:56:08 INFO   Epoch 2/5 - Batch 1000/16000 Done - Train Loss: 0.447905, Val Loss: 0.452635\n",
      "17:56:17 INFO   Epoch 2/5 - Batch 2000/16000 Done - Train Loss: 0.446044, Val Loss: 0.459404\n",
      "17:56:27 INFO   Epoch 2/5 - Batch 3000/16000 Done - Train Loss: 0.444841, Val Loss: 0.466354\n",
      "17:56:37 INFO   Epoch 2/5 - Batch 4000/16000 Done - Train Loss: 0.445659, Val Loss: 0.463104\n",
      "17:56:47 INFO   Epoch 2/5 - Batch 5000/16000 Done - Train Loss: 0.446426, Val Loss: 0.452789\n",
      "17:56:56 INFO   Epoch 2/5 - Batch 6000/16000 Done - Train Loss: 0.446924, Val Loss: 0.457611\n",
      "17:57:06 INFO   Epoch 2/5 - Batch 7000/16000 Done - Train Loss: 0.447464, Val Loss: 0.478938\n",
      "17:57:16 INFO   Epoch 2/5 - Batch 8000/16000 Done - Train Loss: 0.447942, Val Loss: 0.457215\n",
      "17:57:25 INFO   Epoch 2/5 - Batch 9000/16000 Done - Train Loss: 0.447920, Val Loss: 0.464010\n",
      "17:57:35 INFO   Epoch 2/5 - Batch 10000/16000 Done - Train Loss: 0.447962, Val Loss: 0.471124\n",
      "17:57:45 INFO   Epoch 2/5 - Batch 11000/16000 Done - Train Loss: 0.447939, Val Loss: 0.461499\n",
      "17:57:54 INFO   Epoch 2/5 - Batch 12000/16000 Done - Train Loss: 0.447844, Val Loss: 0.468860\n",
      "17:58:04 INFO   Epoch 2/5 - Batch 13000/16000 Done - Train Loss: 0.447773, Val Loss: 0.469214\n",
      "17:58:14 INFO   Epoch 2/5 - Batch 14000/16000 Done - Train Loss: 0.448061, Val Loss: 0.463325\n",
      "17:58:23 INFO   Epoch 2/5 - Batch 15000/16000 Done - Train Loss: 0.448220, Val Loss: 0.461076\n",
      "17:59:16 INFO   Epoch 2/5 - Train Loss: 0.448290, Test Loss: 0.463471, Test ROC Score: 0.790146\n",
      "17:59:26 INFO   Epoch 3/5 - Batch 1000/16000 Done - Train Loss: 0.444086, Val Loss: 0.470733\n",
      "17:59:35 INFO   Epoch 3/5 - Batch 2000/16000 Done - Train Loss: 0.442608, Val Loss: 0.464641\n",
      "17:59:45 INFO   Epoch 3/5 - Batch 3000/16000 Done - Train Loss: 0.441673, Val Loss: 0.465070\n",
      "17:59:55 INFO   Epoch 3/5 - Batch 4000/16000 Done - Train Loss: 0.442635, Val Loss: 0.475393\n",
      "18:00:05 INFO   Epoch 3/5 - Batch 5000/16000 Done - Train Loss: 0.443529, Val Loss: 0.476728\n",
      "18:00:14 INFO   Epoch 3/5 - Batch 6000/16000 Done - Train Loss: 0.444110, Val Loss: 0.458068\n",
      "18:00:24 INFO   Epoch 3/5 - Batch 7000/16000 Done - Train Loss: 0.444714, Val Loss: 0.476368\n",
      "18:00:34 INFO   Epoch 3/5 - Batch 8000/16000 Done - Train Loss: 0.445248, Val Loss: 0.461436\n",
      "18:00:43 INFO   Epoch 3/5 - Batch 9000/16000 Done - Train Loss: 0.445268, Val Loss: 0.467813\n",
      "18:00:53 INFO   Epoch 3/5 - Batch 10000/16000 Done - Train Loss: 0.445333, Val Loss: 0.480495\n",
      "18:01:03 INFO   Epoch 3/5 - Batch 11000/16000 Done - Train Loss: 0.445341, Val Loss: 0.458497\n",
      "18:01:12 INFO   Epoch 3/5 - Batch 12000/16000 Done - Train Loss: 0.445258, Val Loss: 0.461260\n",
      "18:01:22 INFO   Epoch 3/5 - Batch 13000/16000 Done - Train Loss: 0.445203, Val Loss: 0.465380\n",
      "18:01:32 INFO   Epoch 3/5 - Batch 14000/16000 Done - Train Loss: 0.445504, Val Loss: 0.460801\n",
      "18:01:41 INFO   Epoch 3/5 - Batch 15000/16000 Done - Train Loss: 0.445678, Val Loss: 0.458086\n",
      "18:02:34 INFO   Epoch 3/5 - Train Loss: 0.445768, Test Loss: 0.467723, Test ROC Score: 0.787293\n",
      "18:02:44 INFO   Epoch 4/5 - Batch 1000/16000 Done - Train Loss: 0.442310, Val Loss: 0.469795\n",
      "18:02:54 INFO   Epoch 4/5 - Batch 2000/16000 Done - Train Loss: 0.441011, Val Loss: 0.474219\n",
      "18:03:04 INFO   Epoch 4/5 - Batch 3000/16000 Done - Train Loss: 0.440203, Val Loss: 0.469737\n",
      "18:03:13 INFO   Epoch 4/5 - Batch 4000/16000 Done - Train Loss: 0.441225, Val Loss: 0.465328\n",
      "18:03:23 INFO   Epoch 4/5 - Batch 5000/16000 Done - Train Loss: 0.442177, Val Loss: 0.466976\n",
      "18:03:33 INFO   Epoch 4/5 - Batch 6000/16000 Done - Train Loss: 0.442794, Val Loss: 0.479386\n",
      "18:03:42 INFO   Epoch 4/5 - Batch 7000/16000 Done - Train Loss: 0.443423, Val Loss: 0.471983\n",
      "18:03:52 INFO   Epoch 4/5 - Batch 8000/16000 Done - Train Loss: 0.443981, Val Loss: 0.468504\n",
      "18:04:02 INFO   Epoch 4/5 - Batch 9000/16000 Done - Train Loss: 0.444012, Val Loss: 0.470579\n",
      "18:04:11 INFO   Epoch 4/5 - Batch 10000/16000 Done - Train Loss: 0.444080, Val Loss: 0.474295\n",
      "18:04:21 INFO   Epoch 4/5 - Batch 11000/16000 Done - Train Loss: 0.444094, Val Loss: 0.457509\n",
      "18:04:31 INFO   Epoch 4/5 - Batch 12000/16000 Done - Train Loss: 0.444006, Val Loss: 0.476087\n",
      "18:04:41 INFO   Epoch 4/5 - Batch 13000/16000 Done - Train Loss: 0.443949, Val Loss: 0.472143\n",
      "18:04:50 INFO   Epoch 4/5 - Batch 14000/16000 Done - Train Loss: 0.444247, Val Loss: 0.468210\n",
      "18:05:00 INFO   Epoch 4/5 - Batch 15000/16000 Done - Train Loss: 0.444422, Val Loss: 0.477194\n",
      "18:05:52 INFO   Epoch 4/5 - Train Loss: 0.444515, Test Loss: 0.472056, Test ROC Score: 0.784525\n",
      "18:06:02 INFO   Epoch 5/5 - Batch 1000/16000 Done - Train Loss: 0.441309, Val Loss: 0.475399\n",
      "18:06:12 INFO   Epoch 5/5 - Batch 2000/16000 Done - Train Loss: 0.440124, Val Loss: 0.479927\n",
      "18:06:22 INFO   Epoch 5/5 - Batch 3000/16000 Done - Train Loss: 0.439393, Val Loss: 0.464068\n",
      "18:06:31 INFO   Epoch 5/5 - Batch 4000/16000 Done - Train Loss: 0.440452, Val Loss: 0.476763\n",
      "18:06:41 INFO   Epoch 5/5 - Batch 5000/16000 Done - Train Loss: 0.441438, Val Loss: 0.477283\n",
      "18:06:51 INFO   Epoch 5/5 - Batch 6000/16000 Done - Train Loss: 0.442076, Val Loss: 0.490554\n",
      "18:07:00 INFO   Epoch 5/5 - Batch 7000/16000 Done - Train Loss: 0.442717, Val Loss: 0.470544\n",
      "18:07:10 INFO   Epoch 5/5 - Batch 8000/16000 Done - Train Loss: 0.443289, Val Loss: 0.481319\n",
      "18:07:20 INFO   Epoch 5/5 - Batch 9000/16000 Done - Train Loss: 0.443325, Val Loss: 0.482361\n",
      "18:07:29 INFO   Epoch 5/5 - Batch 10000/16000 Done - Train Loss: 0.443390, Val Loss: 0.475876\n",
      "18:07:39 INFO   Epoch 5/5 - Batch 11000/16000 Done - Train Loss: 0.443404, Val Loss: 0.486227\n",
      "18:07:49 INFO   Epoch 5/5 - Batch 12000/16000 Done - Train Loss: 0.443308, Val Loss: 0.473072\n",
      "18:07:59 INFO   Epoch 5/5 - Batch 13000/16000 Done - Train Loss: 0.443247, Val Loss: 0.464976\n",
      "18:08:08 INFO   Epoch 5/5 - Batch 14000/16000 Done - Train Loss: 0.443540, Val Loss: 0.474337\n",
      "18:08:18 INFO   Epoch 5/5 - Batch 15000/16000 Done - Train Loss: 0.443713, Val Loss: 0.475109\n",
      "18:09:11 INFO   Epoch 5/5 - Train Loss: 0.443806, Test Loss: 0.476449, Test ROC Score: 0.781849\n"
     ]
    }
   ],
   "source": [
    "execution.train_model(FM, train_data, test_data, F.binary_cross_entropy_with_logits, torch.optim.Adam(FM.parameters()), DEVICE, checkpoint_dir, checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FM_4', 'FM_1', 'FM_5', 'FM_2', 'FM_3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FM_2D_Layer(len(embedding_map_dict)+60,39,5)\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'FM_1')))\n",
    "model.eval()\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:13:04 INFO   Model ROC Score: 0.805224\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score(model, train_data, DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:13:47 INFO   Model ROC Score: 0.792564\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model ROC Score: {:.6f}'.format(execution.get_roc_auc_score(model, test_data, DEVICE)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
