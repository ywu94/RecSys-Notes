{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.__version__>='1.2.0', 'Expect PyTorch>=1.2.0 but get {}'.format(torch.__version__)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "imp_dir = '../Implementations'\n",
    "sys.path.insert(1, imp_dir)\n",
    "data_dir = '../Data/criteo'\n",
    "sys.path.insert(1, data_dir)\n",
    "\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)\n",
    "\n",
    "log_path = 'xDeepFM_notebook.log'\n",
    "if os.path.isfile(log_path): os.remove(log_path)\n",
    "    \n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)-s: %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "fh = logging.FileHandler(log_path)\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "sh = logging.StreamHandler(sys.stdout)\n",
    "sh.setLevel(logging.INFO)\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:50:38 INFO: Device in Use: cuda\n",
      "17:50:38 INFO: CUDA Memory: Total 11.17 GB, Cached 0.00 GB, Allocated 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info('Device in Use: {}'.format(DEVICE))\n",
    "torch.cuda.empty_cache()\n",
    "t = torch.cuda.get_device_properties(DEVICE).total_memory/1024**3\n",
    "c = torch.cuda.memory_cached(DEVICE)/1024**3\n",
    "a = torch.cuda.memory_allocated(DEVICE)/1024**3\n",
    "logger.info('CUDA Memory: Total {:.2f} GB, Cached {:.2f} GB, Allocated {:.2f} GB'.format(t,c,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map_dict_pkl_path = os.path.join(data_dir, 'criteo_feature_dict_artifact/categorical_feature_map_dict.pkl')\n",
    "with open(embedding_map_dict_pkl_path, 'rb') as f:\n",
    "    embedding_map_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_artifact_dir = os.path.join(data_dir, 'criteo_train_numpy_artifact')\n",
    "index_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='index', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "value_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='value', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "label_artifact = sorted(list(filter(lambda x: x.split('-')[1]=='label', os.listdir(np_artifact_dir))), key = lambda x: int(x.split('.')[0].split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:01:03 INFO: Training data loaded after 4194.25s\n",
      "19:22:22 INFO: Test data loaded after 1279.05s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[:10]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[:10]]),\n",
    ")\n",
    "\n",
    "logger.info('Training data loaded after {:.2f}s'.format(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_data = (\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in index_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in value_artifact[10:]]),\n",
    "    np.vstack([np.load(os.path.join(np_artifact_dir, f)) for f in label_artifact[10:]]),\n",
    ")\n",
    "\n",
    "logger.info('Test data loaded after {:.2f}s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import execution\n",
    "import xDeepFM_BinClf_Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "xDeepFM = xDeepFM_BinClf_Torch.xDeepFM_Layer(len(embedding_map_dict)+60,\n",
    "                                             10,\n",
    "                                             26,\n",
    "                                             13,\n",
    "                                             [400, 400, 400, 400],\n",
    "                                             [0, 0, 0, 0, 0],\n",
    "                                             [100, 100, 100],\n",
    "                                             True\n",
    "                                            ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "checkpoint_dir = os.path.join(cwd, 'xDeepFM_artifact')\n",
    "checkpoint_prefix = 'xDeepFM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04:57:43 INFO: Epoch 1/5 - Batch 1000/8000 Done - Train Loss: 0.461659, Val Loss: 0.458999\n",
      "05:02:25 INFO: Epoch 1/5 - Batch 2000/8000 Done - Train Loss: 0.456410, Val Loss: 0.479403\n",
      "05:07:07 INFO: Epoch 1/5 - Batch 3000/8000 Done - Train Loss: 0.455004, Val Loss: 0.458273\n",
      "05:11:57 INFO: Epoch 1/5 - Batch 4000/8000 Done - Train Loss: 0.454135, Val Loss: 0.432131\n",
      "05:16:46 INFO: Epoch 1/5 - Batch 5000/8000 Done - Train Loss: 0.452750, Val Loss: 0.449463\n",
      "05:21:36 INFO: Epoch 1/5 - Batch 6000/8000 Done - Train Loss: 0.451491, Val Loss: 0.420265\n"
     ]
    }
   ],
   "source": [
    "execution.train_model_separate_inp(xDeepFM, \n",
    "                                   train_data, \n",
    "                                   test_data, \n",
    "                                   F.binary_cross_entropy_with_logits, \n",
    "                                   torch.optim.Adam(xDeepFM.parameters()), \n",
    "                                   DEVICE, \n",
    "                                   checkpoint_dir, \n",
    "                                   checkpoint_prefix,\n",
    "                                   logger=logger\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Sample Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'xDeepFM_BinClf_Torch' from '../Implementations/xDeepFM_BinClf_Torch.py'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import execution\n",
    "importlib.reload(execution)\n",
    "import xDeepFM_BinClf_Torch\n",
    "importlib.reload(xDeepFM_BinClf_Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "xDeepFM = xDeepFM_BinClf_Torch.xDeepFM_Layer(len(embedding_map_dict)+60,\n",
    "                                             10,\n",
    "                                             26,\n",
    "                                             13,\n",
    "                                             [400, 400, 400, 400],\n",
    "                                             [0, 0, 0, 0, 0],\n",
    "                                             [100, 100, 100],\n",
    "                                             True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dense = torch.from_numpy(np.ones((10, 13))).float()\n",
    "inp_sparse = torch.from_numpy(np.arange(260).reshape((10,26))).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0788],\n",
       "        [-0.2363],\n",
       "        [ 0.4149],\n",
       "        [ 0.1767],\n",
       "        [ 0.2753],\n",
       "        [ 0.3456],\n",
       "        [-0.1220],\n",
       "        [ 0.5456],\n",
       "        [ 0.0888],\n",
       "        [ 0.4277]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xDeepFM(inp_dense, inp_sparse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
